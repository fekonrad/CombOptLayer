{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB88y60HUU15JjK80gfSS5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fekonrad/CombOptLayer/blob/main/Demo/COptLayer_Warcraft_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the COptLayer\n",
        "First, let's install the COptLayer repository:"
      ],
      "metadata": {
        "id": "VncOI7_MobSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fekonrad/CombOptLayer.git\n",
        "!cd CombOptLayer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UzGr0dUojQd",
        "outputId": "44324499-22e2-426d-8828-e6578c3f5fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CombOptLayer'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 96 (delta 31), reused 25 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (96/96), 40.63 KiB | 5.80 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and install all necessary libraries:"
      ],
      "metadata": {
        "id": "YPf2sH9UzA6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import CombOptLayer\n",
        "from CombOptLayer import COptLayer\n",
        "from CombOptLayer.losses import PerturbedLoss"
      ],
      "metadata": {
        "id": "QCiXqcxHzDKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Task\n",
        "...\n",
        "\n",
        "This is a short demo on how to use the COptLayer for the toy problem of finding shortest paths on Warcraft maps. To illustrate what the maps, graphs and paths look like, see the plots below:\n"
      ],
      "metadata": {
        "id": "FFAgfvjAoIYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WarcraftPaths(Dataset):\n",
        "    def __init__(self, map_path, cost_path, paths_path):\n",
        "        super().__init__()\n",
        "        self.maps = torch.tensor(np.load(map_path), dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "        self.costs = torch.tensor(np.load(cost_path), dtype=torch.float32)\n",
        "        self.shortest_paths = torch.tensor(np.load(paths_path), dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.maps.shape[0]\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.maps[item], self.costs[item], self.shortest_paths[item]"
      ],
      "metadata": {
        "id": "1a3OywNyqPOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TTGAnc1oEvj"
      },
      "outputs": [],
      "source": [
        "# TODO: Load and plot a sample map"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Model (CNN)\n",
        "We implement a very basic CNN to estimate the vertex costs of the map. Since this problem is not very complex, a relatively small model would suffice."
      ],
      "metadata": {
        "id": "_-PRcUyuo3oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VertexWeightCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # define architecture ...\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding='same')\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, padding='same')\n",
        "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, padding='same')\n",
        "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, padding='same')\n",
        "        self.conv6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, padding='same')\n",
        "        self.final_layer = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=2, padding='same')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param img: torch.tensor of shape (b, c, h, w)      (in our case c=3, h=w=96)\n",
        "        :return: torch.tensor of shape (b, c', h', w')      (in our case c=1, h=w=12)\n",
        "        \"\"\"\n",
        "        x = self.conv1(x)             # (b, 16, 96, 96)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.conv2(x)               # (b, 32, 96, 96)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = nn.MaxPool2d(kernel_size=2)(x)        # (b, 32, 48, 48)\n",
        "\n",
        "        x = self.conv3(x)             # (b, 32, 48, 48)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.conv4(x)               # (b, 32, 96, 96)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = nn.MaxPool2d(kernel_size=2)(x)        # (b, 32, 24, 24)\n",
        "\n",
        "        x = self.conv5(x)             # (b, 32, 24, 24)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.conv6(x)               # (b, 32, 24, 24)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = nn.MaxPool2d(kernel_size=2)(x)        # (b, 32, 12, 12)\n",
        "\n",
        "        return nn.Softplus()(self.final_layer(x)).squeeze(1)  # Softplus to make weights non-negative."
      ],
      "metadata": {
        "id": "fvN6s7omo4kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Combinatorial Solver (Dijkstra)\n",
        "Now we just have to implement our solver for finding shortest paths (given vertex weights) on 2D grids, where  the possible moves at each point are up, down, left, right and diagonal.\n",
        "\n",
        "We have to make sure that the input of our solver is compatible with what our statistical model (the CNN) returns as outputs, i.e. in this case a `torch.tensor` of shape `(b, 1, h, w)`.\n",
        "\n",
        "**Remark:**\n",
        "The COptLayer will have to solve multiple instances of the combinatorial problem at once. Therefore it is clever to try to implement the solver using parallelizable operations, instead of trying to solve the problems sequentially. This means either sticking to what `torch` already has implemented or writing your own parallelized methods e.g. using CUDA."
      ],
      "metadata": {
        "id": "EQiIpKtjolR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement Solver"
      ],
      "metadata": {
        "id": "ToS0IRAyoy4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have everything we need to build the model!\n",
        "Here we use the PerturbedLoss with our implemented solver to train the CNN.\n",
        "\n",
        "*Note:*\n",
        "Technically, we should require the vertex weights to be non-negative, in order to guarantee convergence of the solver. Thus, one could/should use the \"Multiplicative Perturbation discussed in the paper (reference here). Here we simply use the additive perturbation (which might lead to some weights becoming negative!) and the experiments still seem to work fine."
      ],
      "metadata": {
        "id": "Nvdwy9vSp8Rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = VertexWeightCNN().to(DEVICE)\n",
        "solver = dijkstra\n",
        "loss_fn = PerturbedLoss(solver, objective='min', num_samples=10, smoothing=1.0)"
      ],
      "metadata": {
        "id": "mncNwB1EqBzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training routine now works like any other training routine in torch!"
      ],
      "metadata": {
        "id": "mAF093WSqFNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement training routine and monitor sample map.\n",
        "epochs = 10\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# TODO: Maybe fix the paths here.\n",
        "data = WarcraftPaths(\"warcraft-maps-shortest-paths/test_maps.npy\",\n",
        "                     \"warcraft-maps-shortest-paths/test_vertex_weights.npy\",\n",
        "                     \"warcraft-maps-shortest-paths/test_shortest_paths.npy\")\n",
        "\n",
        "dataloader = DataLoader(data, batch_size=16, shuffle=True)\n",
        "steps = 0\n",
        "loss_vals = []\n",
        "\n",
        "for _ in range(epochs):\n",
        "    for maps, weights, paths in dataloader:\n",
        "        maps, weights, paths = maps.to(DEVICE), weights.to(DEVICE), paths.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        vertex_weight_pred = model(maps)\n",
        "        paths_pred = solver(vertex_weight_pred.squeeze(1))\n",
        "        loss = loss_fn(vertex_weight_pred, paths)\n",
        "        loss_val = loss.item()\n",
        "        loss_vals.append(loss_val)\n",
        "        print(f\"Loss after {steps} Steps: {loss_val}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        steps += 1\n",
        "\n",
        "    fig, ax = plt.subplots(ncols=2, nrows=2)\n",
        "    ax[0, 0].imshow(weights[0].cpu().detach().numpy())\n",
        "    ax[0, 1].imshow(model(maps).cpu().detach().numpy()[0])\n",
        "    ax[1, 0].imshow(paths[0].cpu().detach().numpy())\n",
        "    ax[1, 1].imshow(paths_pred[0].cpu().detach().numpy())\n",
        "    plt.show()\n",
        "\n",
        "plt.plot(loss_vals)\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Perturbed Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qaYDNHfoqTU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "..."
      ],
      "metadata": {
        "id": "qztXoLcRqZiA"
      }
    }
  ]
}